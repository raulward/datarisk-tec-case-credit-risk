{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "112339a4",
   "metadata": {},
   "source": [
    "# **Case Técnico – Cientista de Dados Júnior | Datarisk (Modelagem)**\n",
    "\n",
    "Nesta etapa, será desenvolvido um modelo preditivo para estimar a probabilidade de inadimplência associada às cobranças mensais dos clientes. Esse tipo de solução é conhecido como modelo de PD (Probability of Default).\n",
    "\n",
    "O objetivo é identificar, com antecedência, quais clientes apresentam maior propensão a atrasar o pagamento em 5 dias ou mais, conforme definido no problema. Para isso, serão avaliadas diferentes abordagens de modelagem, buscando um equilíbrio entre desempenho preditivo, interpretabilidade e robustez temporal.\n",
    "\n",
    "Dentre os algoritmos considerados, utilizarei:\n",
    "\n",
    "- **Regressão Logística:** modelo clássico em risco de crédito, interpretável e adequado como baseline para avaliação inicial de performance.\n",
    "\n",
    "- **XGBoost (Extreme Gradient Boosting):** método ensemble baseado em árvores de decisão, capaz de capturar relações não lineares e interações complexas entre variáveis, frequentemente apresentando ganhos de performance em comparação a modelos lineares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6281b7a5",
   "metadata": {},
   "source": [
    "**Importando as bibliotecas**\n",
    "\n",
    "\n",
    "* **pandas (pd)**: Leitura, tratamento e manipulação de DataFrames.\n",
    "* **numpy (np)**: Operações numéricas vetorizadas e funções matemáticas.\n",
    "* **matplotlib / pyplot (mpl, plt)**: Criação de gráficos básicos e customização de estilo.\n",
    "* **seaborn (sns)**:  Visualizações estatísticas de alto nível, com paletas personalizadas.\n",
    "* **scikit-learn**: Modelagem e Machine Learning\n",
    "* **joblib**: Salvar pipeline e modelo treinado\n",
    "**Configurações e Estilo**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a926fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, brier_score_loss, confusion_matrix, precision_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import shap\n",
    "\n",
    "import joblib\n",
    "\n",
    "from src.modelling_utils import *\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_info_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mpl.style.use('ggplot')\n",
    "mpl.rcParams['axes.facecolor']      = 'white'\n",
    "mpl.rcParams['grid.color']          = 'lightgray'\n",
    "mpl.rcParams['xtick.color']         = 'black'\n",
    "mpl.rcParams['ytick.color']         = 'black'\n",
    "mpl.rcParams['axes.grid']           = True\n",
    "mpl.rcParams['figure.dpi']          = 150\n",
    "\n",
    "# Palette\n",
    "instyle_palette = ['#006bbe', '#8a817c', '#254278', \"#14155E\", '#96c8e4']\n",
    "progress_palette = ['#00215d', '#00468b', '#0071bc', '#589fef', '#8fd0ff']\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "sns.set_palette(sns.color_palette(instyle_palette))\n",
    "sns.palplot(sns.color_palette(instyle_palette))\n",
    "sns.palplot(sns.color_palette(progress_palette))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b934221f",
   "metadata": {},
   "source": [
    "### **Carregamento e Preparação Inicial dos Dados**\n",
    "\n",
    "A função read_and_clean_data é responsável por realizar a leitura dos arquivos brutos a partir dos caminhos fornecidos. Após o carregamento, essa função aplica as correções, padronizações e tratamentos definidos durante a etapa de EDA, garantindo que todos os datasets utilizados na modelagem estejam consistentes, limpos e prontos para integração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5787f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_and_clean_data('../data/processed/base_pagamentos_desenvolvimento.parquet', file_type='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c63ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef0d78",
   "metadata": {},
   "source": [
    "Para garantir consistência entre as bases e melhorar a capacidade preditiva do modelo, foram extraídos **dia e mês** das variáveis temporais. Essa decomposição facilita a interpretação dos padrões sazonais, reduz a complexidade dos dados de data e permite que o modelo capture melhor efeitos como:\n",
    "\n",
    "* variações mensais ou sazonais de inadimplência;\n",
    "* comportamento associado ao dia de vencimento;\n",
    "* envelhecimento da relação cliente–empresa ao longo do tempo.\n",
    "\n",
    "Além disso, a transformação torna as features mais explicáveis e adequadas para algoritmos lineares e baseados em árvores, preservando integridade e reprodutibilidade na etapa de modelagem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DIA_VENCIMENTO_DOCUMENTO'] = (df['DATA_VENCIMENTO']).dt.day\n",
    "df['MES_VENCIMENTO_DOCUMENTO'] = (df['DATA_VENCIMENTO']).dt.month\n",
    "df['TEMPO_DE_PAGAMENTO'] = (df['DATA_VENCIMENTO'] - df['DATA_EMISSAO_DOCUMENTO']).dt.days\n",
    "df['DIA_REF'] = (df['SAFRA_REF']).dt.day\n",
    "df['MES_REF'] = (df['SAFRA_REF']).dt.month\n",
    "df['ANO_REF'] = (df['SAFRA_REF']).dt.year\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f5c09",
   "metadata": {},
   "source": [
    "Para a variável DATA_CADASTRO, foi criado o tempo de relacionamento do cliente até a data da cobrança, calculado como a diferença em meses entre DATA_CADASTRO e SAFRA_REF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a30d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TEMPO_RELACIONAMENTO'] = (\n",
    "    (df['SAFRA_REF'].dt.year - df['DATA_CADASTRO'].dt.year) * 12 +\n",
    "    (df['SAFRA_REF'].dt.month - df['DATA_CADASTRO'].dt.month)\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e26492a",
   "metadata": {},
   "source": [
    "Após extrair os componentes relevantes das datas (dia e mês) e calcular as métricas temporais necessárias, as colunas originais de data podem ser removidas. Isso evita redundância, reduz dimensionalidade e previne que informações não estruturadas em formato de data impactem negativamente o modelo. Deixarei apenas SAFRA_REF para realizar a separação entre treino e teste, entretanto, ao fazer a separação, ela também será removida.\n",
    "\n",
    "Removerei também, DOMINIO_EMAIL, uma vez que esta variável não carrega valor preditivo satisfatório para a modelagem e não possui nenhuma informação crucial de crédito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa05c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['DATA_EMISSAO_DOCUMENTO', 'DATA_PAGAMENTO', 'DATA_VENCIMENTO', 'DDD', 'CEP_2_DIG', 'DATA_CADASTRO', 'DOMINIO_EMAIL']\n",
    "\n",
    "df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e31d6a",
   "metadata": {},
   "source": [
    "### **Separação: Treino e Teste**\n",
    "\n",
    "Para garantir consistência temporal e evitar que o modelo tenha acesso a informações futuras, foi adotado um split Out-of-Time (OOT). Esse tipo de divisão utiliza períodos mais antigos para treino e períodos mais recentes para teste, respeitando a cronologia natural das cobranças. Dessa forma, avaliamos o modelo em um cenário que simula corretamente sua aplicação real, onde previsões são feitas sempre para períodos posteriores aos utilizados no treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd5580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = np.split(df, [int(.80 * len(df))])\n",
    "\n",
    "train['SET'] = 'train'\n",
    "test['SET'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad44664",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Taxa de inadimplente conjunto de treino:\\n {train['TARGET'].value_counts(normalize=True)}.\")\n",
    "print()\n",
    "print(f\"Taxa de inadimplente conjunto de teste:\\n {test['TARGET'].value_counts(normalize=True)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d74464",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'O conjunto de treino tem {train.shape[0]} linhas e {train.shape[1]} colunas')\n",
    "print(f'O conjunto de teste tem {test.shape[0]} linhas e {test.shape[1]} colunas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aba12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.concat([train, test])\n",
    "train_test = (\n",
    "    train_test\n",
    "    .groupby(['SAFRA_REF', 'SET'])['TARGET']\n",
    "    .count()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "plt.title('Out-of-time Split', fontsize=15)\n",
    "\n",
    "for set_name, df_set in train_test.groupby('SET'):\n",
    "    ax.plot(df_set['SAFRA_REF'], df_set['TARGET'], marker='o', label=set_name)\n",
    "\n",
    "ax.set_ylabel('Quantidade de empréstimos')\n",
    "ax.legend()\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc850e1b",
   "metadata": {},
   "source": [
    "Observamos o OoT Split no gráfico acima. Em cinza, estão os dados de treinamento e em azul, os dados de teste. O intuito é respeitar a ordem cronólogica das cobranças e garantir que o modelo seja avaliado em um cenário realista, o qual previsões são feitas apenas em períodos futuros em relação aos dados de treinamento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = df.isna().sum().to_frame().rename(columns={0: 'count'}).sort_values(by=['count'], ascending=False)\n",
    "missing_df['pct'] = round(missing_df['count'] / df.shape[0] * 100, 3)\n",
    "missing_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0453d",
   "metadata": {},
   "source": [
    "### **Análise de Valores Ausentes**\n",
    "\n",
    "A tabela acima apresenta a quantidade e o percentual de valores faltantes por variável no dataset. Observamos que:\n",
    "\n",
    "* **REGIAO_DDD** e **RENDA_MES_ANTERIOR** possuem os maiores percentuais de missing, acima de 5%.\n",
    "* Variáveis como **REGIAO_DDD**, **PORTE** e **SEGMENTO_INDUSTRIAL** apresentam níveis moderados de ausência.\n",
    "* A maior parte das variáveis apresenta **pouco ou nenhum missing**, o que reduz a necessidade de tratamentos agressivos.\n",
    "\n",
    "Com base nesses resultados, aplicaremos estratégias de imputação adequadas ao tipo da variável (numérica ou categórica), garantindo consistência durante o pré-processamento e evitando perda de informação.\n",
    "\n",
    "### **Modelagem: Baseline**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f942ca",
   "metadata": {},
   "source": [
    "**Separação entre treino e teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd3a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['TARGET', 'ID_CLIENTE', 'SAFRA_REF'], axis=1)\n",
    "y_train = train['TARGET']\n",
    "X_test = test.drop(['TARGET', 'ID_CLIENTE', 'SAFRA_REF'], axis=1)\n",
    "y_test = test['TARGET']\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868910a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    'VALOR_A_PAGAR',\n",
    "    'RENDA_MES_ANTERIOR',\n",
    "    'NO_FUNCIONARIOS',\n",
    "    'DIA_VENCIMENTO_DOCUMENTO',\n",
    "    'MES_VENCIMENTO_DOCUMENTO',\n",
    "    'DIA_REF',\n",
    "    'MES_REF',\n",
    "    'TEMPO_RELACIONAMENTO'\n",
    "]\n",
    "\n",
    "cat_cols = [\n",
    "    'FLAG_PF',\n",
    "    'TAXA',\n",
    "    'SEGMENTO_INDUSTRIAL',\n",
    "    'PORTE',\n",
    "    'REGIAO_DDD',\n",
    "    'REGIAO_CEP'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1104d7",
   "metadata": {},
   "source": [
    "## **Pré-processamento das variáveis**\n",
    "\n",
    "Antes da etapa de modelagem, é fundamental garantir que todas as variáveis estejam estruturadas de forma adequada para os algoritmos utilizados. Para isso, definimos três fluxos de tratamento distintos: **variáveis numéricas**, **variáveis categóricas**.\n",
    "\n",
    "Esse processo assegura consistência, evita problemas de escala, trata valores ausentes e organiza a informação de modo a maximizar o poder preditivo do modelo.\n",
    "\n",
    "\n",
    "### **1. Variáveis Numéricas**\n",
    "\n",
    "As variáveis numéricas passam por duas etapas principais: **imputação** e **padronização**.\n",
    "\n",
    "1. **Imputação por mediana**\n",
    "   Valores ausentes são substituídos pela mediana da variável. Essa estratégia é robusta a outliers e evita que valores extremos distorçam a imputação.\n",
    "\n",
    "2. **Padronização (StandardScaler)**\n",
    "   Após a imputação, cada variável é transformada para uma escala comum, com média zero e desvio-padrão igual a um:\n",
    "\n",
    "$$[\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "]$$\n",
    "\n",
    "Essa padronização é importante especialmente para modelos lineares, garantindo que a magnitude das variáveis não influencie de forma desigual o processo de otimização.\n",
    "\n",
    "Esse pipeline assegura que todas as variáveis numéricas sejam interpretadas em uma mesma escala e sem valores faltantes.\n",
    "\n",
    "\n",
    "### **2. Variáveis Categóricas**\n",
    "\n",
    "As variáveis categóricas são tratadas por meio de **imputação** e **codificação**.\n",
    "\n",
    "1. **Imputação por categoria mais frequente (moda)**\n",
    "   Valores ausentes são substituídos pela categoria mais comum da variável. Isso preserva a distribuição original e evita introduzir categorias artificiais.\n",
    "\n",
    "2. **Codificação via One-Hot Encoding**\n",
    "   Cada categoria é convertida em uma coluna binária, permitindo que o modelo utilize corretamente essas variáveis. \n",
    "\n",
    "Esse procedimento garante que toda variável categórica possa ser utilizada em modelos lineares e de árvore sem perda de informação.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de015bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_preproc = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_preproc = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_preproc, num_cols),\n",
    "        ('cat', cat_preproc, cat_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36572c59",
   "metadata": {},
   "source": [
    "### **Pipeline de Modelagem**\n",
    "\n",
    "Para a etapa de modelagem, adotamos dois algoritmos complementares: **Regressão Logística**, como modelo base interpretável, e **XGBoost**, como método de aprendizado de máquina mais robusto e capaz de capturar relações não lineares entre variáveis. Essa combinação permite avaliar desempenho, interpretabilidade e estabilidade temporal no contexto de previsão de inadimplência.\n",
    "\n",
    "#### **1. Regressão Logística**\n",
    "\n",
    "A Regressão Logística é um modelo estatístico utilizado em risco de crédito por sua simplicidade e capacidade de estimar probabilidades. A probabilidade de inadimplência é modelada por meio da função logística:\n",
    "\n",
    "$$\n",
    "P(Y = 1 \\mid X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_k x_k)}}\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "- $Y = 1$ indica inadimplência,  \n",
    "- $X = (x_1, x_2, \\dots, x_k)$ representa o vetor de variáveis explicativas,  \n",
    "- $\\beta = (\\beta_0, \\beta_1, \\dots, \\beta_k)$ são os coeficientes estimados.\n",
    "\n",
    "A função logística transforma a combinação linear das variáveis em uma probabilidade entre 0 e 1.  \n",
    "\n",
    "#### **2. XGBoost (Extreme Gradient Boosting)**\n",
    "\n",
    "O XGBoost é um algoritmo baseado em **árvores de decisão**, construído sob o paradigma de **boosting gradiente**. O método treina diversas árvores sequencialmente, onde cada árvore tenta corrigir os erros da anterior, permitindo capturar interações complexas entre as variáveis.\n",
    "\n",
    "O objetivo do modelo pode ser escrito como:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\phi) = \\sum_{i=1}^{n} l(y_i, \\hat{y}_i) + \\sum_{t=1}^{T} \\Omega(f_t)\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "- $l(y_i, \\hat{y}_i)$ é a função de perda (por exemplo, perda logística),  \n",
    "- $f_t$ é a árvore adicionada na iteração $t$,  \n",
    "- $\\Omega(f_t)$ é um termo de regularização que controla a complexidade do modelo (profundidade, número de folhas etc.).\n",
    "\n",
    "A atualização de cada árvore é feita aproximando o gradiente da função de perda com respeito às previsões anteriores:\n",
    "\n",
    "$$\n",
    "g_i = \\frac{\\partial l(y_i, \\hat{y}_i)}{\\partial \\hat{y}_i}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874bdc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    max_iter=500,\n",
    "    class_weight=None,\n",
    "    fit_intercept=True,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "baseline_log_reg = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', logreg)\n",
    "])\n",
    "\n",
    "baseline_log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_log_reg = baseline_log_reg.predict(X_test)\n",
    "y_probas_log_reg = baseline_log_reg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd38f118",
   "metadata": {},
   "source": [
    "### **Métricas de Discriminação e Calibração**\n",
    "\n",
    "Para avaliar a qualidade de um modelo de inadimplência, utilizamos métricas que medem quão bem ele separa bons e maus pagadores (**discriminação**) e quão bem as probabilidades previstas refletem a realidade (**calibração**). Aqui destacamos quatro métricas centrais: **AUC**, **KS**, **Gini** e **Brier Score**.\n",
    "\n",
    "\n",
    "#### **1. AUC – Area Under the ROC Curve**\n",
    "\n",
    "A AUC mede a capacidade do modelo de **ranquear corretamente** clientes inadimplentes acima dos adimplentes, considerando todos os possíveis pontos de corte.\n",
    "\n",
    "Intuitivamente, a AUC é a probabilidade de que, escolhendo um cliente inadimplente e um adimplente ao acaso, o modelo atribua um score maior ao inadimplente.\n",
    "\n",
    "\n",
    "#### **2. KS – Kolmogorov–Smirnov Statistic**\n",
    "\n",
    "O KS mede a **máxima separação** entre as distribuições acumuladas de score para adimplentes e inadimplentes.\n",
    "\n",
    "Sejam:\n",
    "- $F_1(s)$: função distribuição acumulada (CDF) dos scores para inadimplentes  \n",
    "- $F_0(s)$: CDF dos scores para adimplentes  \n",
    "\n",
    "O KS é definido como:\n",
    "\n",
    "$$\n",
    "KS = \\max_s \\left| F_1(s) - F_0(s) \\right|\n",
    "$$\n",
    "\n",
    "Quanto maior o KS, melhor o modelo consegue separar as duas populações.  \n",
    "\n",
    "\n",
    "#### **3. Gini Coefficient**\n",
    "\n",
    "O coeficiente de Gini é uma transformação linear da AUC:\n",
    "\n",
    "$$\n",
    "Gini = 2 \\cdot AUC - 1\n",
    "$$\n",
    "\n",
    "Assim, um modelo com AUC = 0{,}75 terá:\n",
    "\n",
    "$$\n",
    "Gini = 2 \\cdot 0{,}75 - 1 = 0{,}5\n",
    "$$\n",
    "\n",
    "Indica a qualidade do modelo\n",
    "\n",
    "#### **4. Brier Score**\n",
    "\n",
    "O Brier Score avalia a **calibração** das probabilidades previstas. Ele mede o erro quadrático médio entre as probabilidades estimadas $\\hat{p}_i$ e os resultados reais $y_i \\in \\{0,1\\}$:\n",
    "\n",
    "$$\n",
    "BS = \\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i - \\hat{p}_i \\right)^2\n",
    "$$\n",
    "\n",
    "- Quanto **menor** o Brier, melhor a calibração.  \n",
    "- Um modelo bem calibrado atribui, por exemplo, cerca de 10% de inadimplência para grupos onde de fato ~10% se tornam inadimplentes.\n",
    "\n",
    "Enquanto AUC, KS e Gini focam em quão bem o modelo ordena os clientes por risco, o Brier Score responde o quão confiáveis são as probabilidades numéricas produzidas pelo modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcecd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_test = evaluate_global_metrics(y_test, y_probas_log_reg)\n",
    "\n",
    "pd.DataFrame(metrics_test, index=['metrics']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3782de3a",
   "metadata": {},
   "source": [
    "O modelo baseline apresenta desempenho sólido, com poder discriminativo adequado (AUC ≈ 0.75, KS ≈ 0.40, Gini ≈ 0.50) e excelente calibração (Brier ≈ 0.055). Esses resultados indicam que o modelo separa bem clientes de diferentes níveis de risco e fornece probabilidades consistentes com o comportamento observado nos dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c6425",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test, y_probas_log_reg, title='Curva ROC - Regressão Logística')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ccb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "baseline_xgb = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', xgb)\n",
    "])\n",
    "\n",
    "baseline_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e8771",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_xgb = baseline_xgb.predict(X_test)\n",
    "y_probas_xgb = baseline_xgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6df64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_test = evaluate_global_metrics(y_test, y_probas_xgb)\n",
    "\n",
    "pd.DataFrame(metrics_test, index=['metrics']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668600db",
   "metadata": {},
   "source": [
    "O modelo XGBoost superou amplamente o baseline linear, apresentando excelente capacidade discriminativa (AUC ≈ 0.83, KS ≈ 0.58, Gini ≈ 0.67) e notável calibração (Brier ≈ 0.045). O modelo demonstra maturidade estatística, estabilidade operacional e clareza na separação dos perfis de risco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74fbbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test, y_probas_xgb, title='Curva ROC - XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e97ef6",
   "metadata": {},
   "source": [
    "### **Conclusão sobre os modelos baseline**\n",
    "\n",
    "- A partir da avaliação das métricas de cada modelo acima, pode-se chegar nas seguintes conclusões:\n",
    "    - O modelo de Regressão Logística apresentou métricas satisfatórias, com ROC-AUC em torno de pouco mais de 0,72. Um excelente coeficiente para um base modelo como a Reg. Log., que é computacionalmente mais barato e um modelo mais interpretável.\n",
    "    - O modelo de boosting (XGBoost) apresentou um desempenho significativamente maior, cerca de mais de 0,82 de coeficiente AUC. Isso denota a força e a performance do algoritmo, que é conhecido por lidar melhor com problemas de multicolinearidade.\n",
    "\n",
    "- A Regressão Logística apresenta custo computacional substancialmente menor do que métodos baseados em árvores, como o XGBoost. Por operar com otimização convexa e prever por meio de uma simples combinação linear de variáveis.\n",
    "\n",
    "### **Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = baseline_log_reg.named_steps['preprocess'].get_feature_names_out()\n",
    "\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_log = get_logreg_importance(baseline_log_reg, feature_names)\n",
    "imp_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24c70a",
   "metadata": {},
   "source": [
    "#### **Interpretação dos Coeficientes da Regressão Logística**\n",
    "\n",
    "Os coeficientes indicam o impacto de cada variável na probabilidade de inadimplência:\n",
    "\n",
    "* **coeficiente positivo → aumenta o risco**,\n",
    "* **coeficiente negativo → reduz o risco**.\n",
    "A magnitude (abs_coef) indica importância.\n",
    "\n",
    "**1. Geografia é o principal fator de risco**\n",
    "Regiões de CEP e DDD dominam o topo da lista (ex.: `REGIAO_CEP_8`, `REGIAO_CEP_2`, `REGIAO_DDD_1`, `REGIAO_CEP_5`, `REGIAO_DDD_2`). O risco varia fortemente entre regiões, refletindo diferenças socioeconômicas.\n",
    "\n",
    "**2. Variáveis cadastrais influenciam o comportamento**\n",
    "* `PORTE_GRANDE` reduz risco.\n",
    "* `FLAG_PF_0` (empresas) e segmentos industriais aparecem como redutores, ou seja, perfis mais estruturados têm menor inadimplência.\n",
    "\n",
    "**3. Variáveis financeiras têm efeito moderado**\n",
    "* `VALOR_A_PAGAR` tem coeficiente negativo: valores maiores estão associados a menor risco, sugerindo clientes mais robustos.\n",
    "\n",
    "**4. Variáveis temporais importam**\n",
    "* `MES_VENCIMENTO_DOCUMENTO`, `DIA_VENCIMENTO_DOCUMENTO` e `MES_REF` aparecem, mas com baixa magnitude. Indicam presença de sazonalidade, porém com impacto menor frente às variáveis geográficas e cadastrais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c51c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = baseline_xgb.named_steps['preprocess']\n",
    "xgb  = baseline_xgb.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36abef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = prep.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = prep.get_feature_names_out()\n",
    "\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgb)\n",
    "shap_values = explainer.shap_values(X_train_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_train_trans, feature_names=feature_names, show=False)\n",
    "plt.title(\"SHAP Summary Plot - XGBoost\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fbc1e6",
   "metadata": {},
   "source": [
    "#### **Interpretação do SHAP**\n",
    "\n",
    "O SHAP Summary Plot mostra o impacto de cada variável nas previsões do XGBoost. As variáveis superiores são as mais relevantes; pontos rosados indicam valores altos e azulados valores baixos. A posição no eixo X reflete se a variável aumenta ou reduz a probabilidade de inadimplência.\n",
    "\n",
    "**1. Variáveis financeiras e comportamentais lideram o risco**\n",
    "\n",
    "* **`VALOR_A_PAGAR`** é a variável mais influente. Valores mais altos tendem a **reduzir o risco**, indicando que cobranças maiores estão associadas a clientes mais estáveis.\n",
    "* **`TEMPO_RELACIONAMENTO`** mostra que clientes antigos têm menor inadimplência, enquanto novos concentram maior risco.\n",
    "\n",
    "**2. Forte presença de sazonalidade e efeitos temporais**\n",
    "Variáveis como `MES_VENCIMENTO_DOCUMENTO`, `MES_REF` e `DIA_VENCIMENTO_DOCUMENTO` revelam que o modelo captura padrões de época: alguns meses e dias estão associados a maior probabilidade de atraso, refletindo ciclos financeiros previsíveis.\n",
    "\n",
    "**3. Perfil empresarial influencia o comportamento de pagamento**\n",
    "Features relacionadas ao porte e segmento (`PORTE_GRANDE`, `PORTE_PEQUENO`, `SEGMENTO_Comércio`, `SEGMENTO_Serviços`) destacam que empresas maiores ou de setores mais estruturados apresentam risco menor.\n",
    "\n",
    "**4. Fatores geográficos têm peso relevante**\n",
    "Regiões de CEP e DDD, como `REGIAO_CEP_8`, aparecem entre as variáveis mais importantes, sugerindo **variação regional consistente no risco de inadimplência**.\n",
    "\n",
    "**5. Coerência com análises anteriores**\n",
    "O comportamento captado pelo XGBoost reforça tendências já observadas em modelos lineares:\n",
    "\n",
    "* valor, tempo de relacionamento, fatores temporais e características cadastrais são determinantes no risco.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f05a7",
   "metadata": {},
   "source": [
    "### **Feature Engineering: Comportamento e Saúde Financeira**\n",
    "Para aumentar o poder preditivo sem incorrer em vazamento de dados (data leakage), vou criar variáveis que olham estritamente para o passado (safra anterior) ou para a estrutura financeira atual do cliente:\n",
    "\n",
    "Variáveis de Histórico (Behavior):\n",
    "\n",
    "`HIST_INAD_ANTERIOR`: Soma acumulada de vezes que o cliente atrasou > 5 dias em safras passadas. Captura o \"hábito\" de não pagar.\n",
    "\n",
    "`HIST_FREQ_3M`: Média de inadimplência nos últimos 3 meses fechados. Indica deterioração recente.\n",
    "\n",
    "`N_COBRANCAS`: Total de cobranças identificadas por usuário e safra.\n",
    "\n",
    "Variáveis Financeiras (Capacity & Volatility):\n",
    "\n",
    "`DTI_FATURAMENTO`: Razão entre o valor do boleto e a renda mensal estimada (Debt-to-Income). Indica se a dívida cabe no bolso da empresa.\n",
    "\n",
    "`PAYMENT_SHOCK`: Razão entre o boleto atual e a média dos pagamentos recentes. Se alto (>1.5), indica um gasto atípico que pode gerar quebra de caixa.\n",
    "\n",
    "`TICKET_POR_FUNC`: Valor da dívida dividido pelo número de funcionários. Proxy para o porte e robustez da empresa frente à dívida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = feature_engineering(df)\n",
    "\n",
    "new_features = [\n",
    "    'HIST_INAD_ANTERIOR', 'HIST_FREQ_3M',\n",
    "    'PAYMENT_SHOCK', 'DTI_FATURAMENTO',\n",
    "    'TICKET_POR_FUNC', 'MEDIA_VALOR_3M',\n",
    "    'N_COBRANCAS'\n",
    "]\n",
    "\n",
    "num_cols_fe = list(set(num_cols + new_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f63ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fe, test_fe = np.split(df_fe, [int(.80 * len(df))])\n",
    "\n",
    "train_fe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f9aee",
   "metadata": {},
   "source": [
    "Pode-se separar novamente o conjunto de dados em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fa1ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fe = train_fe.drop(['TARGET', 'ID_CLIENTE', 'SAFRA_REF', 'ANO_REF'], axis=1)\n",
    "y_train_fe = train_fe['TARGET']\n",
    "X_test_fe = test_fe.drop(['TARGET', 'ID_CLIENTE', 'SAFRA_REF', 'ANO_REF'], axis=1)\n",
    "y_test_fe = test_fe['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a31456",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_preproc_fe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_preproc_fe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor_fe = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_preproc_fe, num_cols_fe),\n",
    "        ('cat', cat_preproc_fe, cat_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0025d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_log_reg = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor_fe),\n",
    "    ('clf', logreg)\n",
    "])\n",
    "\n",
    "fe_log_reg.fit(X_train_fe, y_train_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_fe_log_reg = fe_log_reg.predict(X_test_fe)\n",
    "y_probas_fe_log_reg = fe_log_reg.predict_proba(X_test_fe)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_test = evaluate_global_metrics(y_test_fe, y_probas_fe_log_reg)\n",
    "\n",
    "pd.DataFrame(metrics_test, index=['metrics']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b5178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test_fe, y_probas_fe_log_reg, title='Curva ROC - Regressão Logística com FE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6124f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_log_reg.named_steps['preprocess'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120fe058",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = fe_log_reg.named_steps['preprocess'].get_feature_names_out()\n",
    "imp_log = get_logreg_importance(fe_log_reg, feature_names)\n",
    "imp_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f36bbc1",
   "metadata": {},
   "source": [
    "### **Comparação dos coefiecientes**\n",
    "\n",
    "A nova regressão logística apresenta um perfil distinto da anterior, refletindo a inclusão de variáveis comportamentais e uma reorganização clara da importância relativa das features.\n",
    "\n",
    "**1. Histórico comportamental**\n",
    "Diferente dos coeficientes anteriores, dominada por efeitos geográficos e cadastrais, a criação das novas features traz:\n",
    "- `PAYMENT_SHOCK` (negativo → reduz risco)\n",
    "- `HIST_FREQ_3M` (positivo → aumenta risco)\n",
    "- `HIST_INAD_ANTERIOR` (positivo)\n",
    "Essas variáveis aparecem entre as mais importantes, indicando que **o modelo linear passou a capturar comportamento recente**.\n",
    "\n",
    "**2. Geografia segue relevante, mas menos dominante**\n",
    "Variáveis como `REGIAO_CEP_8`, `REGIAO_DDD_0`, `REGIAO_CEP_6`, `REGIAO_DDD_4` continuam com grande magnitude — porém não são mais o único bloco relevante.  \n",
    "**A dependência de localização diminuiu**, indicando um modelo mais equilibrado.\n",
    "\n",
    "**3. Perfil cadastral mantém efeito consistente**\n",
    "- `PORTE_GRANDE` e `PORTE_MEDIO` continuam reduzindo risco.  \n",
    "- `FLAG_PF_0` (empresas) permanece como redutor de inadimplência.  \n",
    "Os padrões continuam coerentes com a regressão anterior.\n",
    "\n",
    "**4. Variáveis financeiras e de porte ganham nuances**\n",
    "- `VALOR_A_PAGAR` e `TICKET_POR_FUNC` aparecem com coeficientes negativos moderados.  \n",
    "- Empresas com maior faturamento (proxy de renda/porte) tendem a inadimplir menos.\n",
    "\n",
    "**5. Menor peso das variáveis temporais**\n",
    "Diferente dos coeficientes anteriores, onde ano/mês tinham grande magnitude, aqui:\n",
    "- `MES_VENCIMENTO_DOCUMENTO`, `MES_REF` e `DIA_VENCIMENTO_DOCUMENTO` aparecem **com magnitudes reduzidas**.  \n",
    "O modelo ficou **menos sensível à sazonalidade** e mais dependente do comportamento histórico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_xgb = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor_fe),\n",
    "    ('clf', xgb)\n",
    "])\n",
    "\n",
    "fe_xgb.fit(X_train_fe, y_train_fe)\n",
    "y_preds_fe_xgb = fe_xgb.predict(X_test_fe)\n",
    "y_probas_fe_xgb = fe_xgb.predict_proba(X_test_fe)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047feaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_test = evaluate_global_metrics(y_test_fe, y_probas_fe_xgb)\n",
    "\n",
    "pd.DataFrame(metrics_test, index=['metrics']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test_fe, y_probas_fe_xgb, title='Curva ROC - XGBoost com FE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = fe_xgb.named_steps['preprocess']\n",
    "xgb  = fe_xgb.named_steps['clf']\n",
    "\n",
    "X_train_trans = prep.transform(X_train_fe)\n",
    "feature_names = prep.get_feature_names_out()\n",
    "\n",
    "feature_names\n",
    "explainer = shap.TreeExplainer(xgb)\n",
    "shap_values = explainer.shap_values(X_train_trans)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_train_trans, feature_names=feature_names, show=False)\n",
    "plt.title(\"SHAP Summary Plot - FE XGBoost\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d07bb6",
   "metadata": {},
   "source": [
    "### **Comparação dos SHAPs**\n",
    "\n",
    "O segundo SHAP mostra um modelo claramente **mais robusto** que o primeiro.\n",
    "\n",
    "**1. Histórico passou a ser a 'categoria' mais importante**\n",
    "- No novo modelo, variáveis como `HIST_INAD_ANTERIOR`, `HIST_FREQ_3M`, `N_COBRANCAS` e `PAYMENT_SHOCK` aparecem no topo. O modelo passa a usar **comportamento passado**, muito mais preditivo que valor, porte ou região.\n",
    "\n",
    "**2. Menor dependência de sazonalidade**\n",
    "- Variáveis de mês e dia continuam relevantes, mas **perdem peso** porque o modelo agora tem boas features comportamentais.\n",
    "\n",
    "**3. Cadastral e geografia**\n",
    "- Porte, segmento e regiões ainda ajudam, porém deixam de dominar o risco.\n",
    "\n",
    "**4. `VALOR_A_PAGAR` perde um pouco de espaço**\n",
    "- Antes era a principal variável, agora é apenas mais uma entre outras importantes, indicando melhor equilíbrio das fontes de informação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153be19",
   "metadata": {},
   "source": [
    "### **Comparação entre os modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"Regressão Logística s/ FE\": {\n",
    "        \"model\": baseline_log_reg,\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_valid\": X_test,\n",
    "        \"y_valid\": y_test,\n",
    "    },\n",
    "    \"XGBoost s/ FE\": {\n",
    "        \"model\": baseline_xgb,\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_valid\": X_test,\n",
    "        \"y_valid\": y_test,\n",
    "    },\n",
    "    \"Regressão Logística c/ FE\": {\n",
    "        \"model\": fe_log_reg,\n",
    "        \"X_train\": X_train_fe,\n",
    "        \"y_train\": y_train_fe,\n",
    "        \"X_valid\": X_test_fe,\n",
    "        \"y_valid\": y_test_fe,\n",
    "    },\n",
    "    \"XGBoost c/ FE\": {\n",
    "        \"model\": fe_xgb,\n",
    "        \"X_train\": X_train_fe,\n",
    "        \"y_train\": y_train_fe,\n",
    "        \"X_valid\": X_test_fe,\n",
    "        \"y_valid\": y_test_fe,\n",
    "    },\n",
    "}\n",
    "\n",
    "results_df, y_scores_dict = compare_model_variants(\n",
    "    experiments,\n",
    "    plot_roc=True,\n",
    "    plot_pr=True,\n",
    "    plot_bar=True,\n",
    "    title_roc=\"Curvas ROC - Comparação de Modelos\"\n",
    ")\n",
    "\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5061f5",
   "metadata": {},
   "source": [
    "### **Conclusão e Escolha do Modelo**\n",
    "\n",
    "Após a avaliação em Out-of-Time (OOT), o XGBoost com Feature Engineering demonstrou superioridade clara frente à Regressão Logística com e sem o processo de seleção e ao XGBoost sem este processo.:\n",
    "\n",
    "- **Discriminação (AUC & KS)**: O XGBoost c/ FE obteve maior capacidade de separar bons de maus pagadores, capturando relações não lineares (ex: o risco de um `PAYMENT_SHOCK` alto pode ser mitigado se o `TEMPO_RELACIONAMENTO` for longo).\n",
    "- **Calibração (Brier Score)**: O modelo apresentou probabilidades consistentes com a taxa real de inadimplência.\n",
    "\n",
    "Decisão: Seguiremos com o XGBoost c/ FE para a submissão final, pois ele maximiza a detecção de inadimplentes mantendo uma taxa de falsos positivos controlada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c97105",
   "metadata": {},
   "source": [
    "### **Modelo salvo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1569d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = '../credit_risk_pipeline.pkl'\n",
    "joblib.dump(fe_xgb, model_filename)\n",
    "print(f\"Pipeline salvo com sucesso em: {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
